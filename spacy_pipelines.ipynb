{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "9O1yVK_7Q6hf"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## blank pipeline\n"
      ],
      "metadata": {
        "id": "zFmNuC65UyFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n",
        "\n",
        "for token in doc:\n",
        "    print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tsr0wey_RE07",
        "outputId": "ea336cb8-dc17-4d0e-cec1-78a14663d36a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Captain\n",
            "america\n",
            "ate\n",
            "100\n",
            "$\n",
            "of\n",
            "samosa\n",
            ".\n",
            "Then\n",
            "he\n",
            "said\n",
            "I\n",
            "can\n",
            "do\n",
            "this\n",
            "all\n",
            "day\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# as it is a balnk pipeline it won't give me anything except the token\n",
        "for token in doc:\n",
        "    print(token, \" | \", token.pos_, \" | \", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fSSe5d0To9Y",
        "outputId": "057267ed-792f-409a-da09-4f7c3dc804cd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Captain  |    |  \n",
            "america  |    |  \n",
            "ate  |    |  \n",
            "100  |    |  \n",
            "$  |    |  \n",
            "of  |    |  \n",
            "samosa  |    |  \n",
            ".  |    |  \n",
            "Then  |    |  \n",
            "he  |    |  \n",
            "said  |    |  \n",
            "I  |    |  \n",
            "can  |    |  \n",
            "do  |    |  \n",
            "this  |    |  \n",
            "all  |    |  \n",
            "day  |    |  \n",
            ".  |    |  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzGY-RAgRHxb",
        "outputId": "36f62d95-f0bd-45fe-a47d-c91f89eacc8f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## trained pipeline\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mVOqLIoCU88W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvAoGUx_RVv9",
        "outputId": "b924539a-4407-43b6-a834-86cb97916b2b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEj1cz26RnJO",
        "outputId": "a6a324de-0b43-4376-d4cb-d34023866271"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7ee5a3d2a500>),\n",
              " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7ee5a08e7940>),\n",
              " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7ee5a3cab1b0>),\n",
              " ('attribute_ruler',\n",
              "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7ee5a0707b80>),\n",
              " ('lemmatizer',\n",
              "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7ee5a3d0a500>),\n",
              " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7ee5a3cab610>)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n",
        "\n",
        "for token in doc:\n",
        "    print(token, \" | \", spacy.explain(token.pos_), \" | \", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C63aMRxQRred",
        "outputId": "75d3ee5b-fe6b-4c1c-fd89-16bc206d3981"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Captain  |  proper noun  |  Captain\n",
            "america  |  proper noun  |  america\n",
            "ate  |  verb  |  eat\n",
            "100  |  numeral  |  100\n",
            "$  |  numeral  |  $\n",
            "of  |  adposition  |  of\n",
            "samosa  |  proper noun  |  samosa\n",
            ".  |  punctuation  |  .\n",
            "Then  |  adverb  |  then\n",
            "he  |  pronoun  |  he\n",
            "said  |  verb  |  say\n",
            "I  |  pronoun  |  I\n",
            "can  |  auxiliary  |  can\n",
            "do  |  verb  |  do\n",
            "this  |  pronoun  |  this\n",
            "all  |  determiner  |  all\n",
            "day  |  noun  |  day\n",
            ".  |  punctuation  |  .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5Yhw_cGR1mp",
        "outputId": "4191a8d7-c38b-4607-9fc3-6f481231adc4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla Inc  |  ORG  |  Companies, agencies, institutions, etc.\n",
            "$45 billion  |  MONEY  |  Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "displacy.render(doc, style=\"ent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "FYMReVD8SuSC",
        "outputId": "b7e35208-7e56-4c84-d646-6bb617832680"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tesla Inc\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is going to acquire twitter for \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    $45 billion\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding a component to a blank pipeline"
      ],
      "metadata": {
        "id": "cNXUs03FVFcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "nlp.add_pipe(\"ner\", source=source_nlp)\n",
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bqTYkHdTVtK",
        "outputId": "965b5d3f-9569-4aca-82ef-a7e35eb89eda"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ner']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP3xnbSNVduo",
        "outputId": "beee32eb-a278-4605-aedf-580b571d40ad"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla Inc  |  ORG  |  Companies, agencies, institutions, etc.\n",
            "$45 billion  |  MONEY  |  Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bfrf631GVgfZ"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}