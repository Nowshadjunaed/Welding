{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<b> stemming </b><br>\n",
        "use fixed rules such as removing ing and able from the end of the word to generate the base words. <br>\n",
        "<br>\n",
        "But but stemming won't always give you the base word such as by stemming you won't find eat from ate. <br>\n",
        "<br>\n",
        "<b> lemmatization </b> <br>\n",
        "use knowledge of a language to derive base word. Here base word is called lemma.\n",
        "\n"
      ],
      "metadata": {
        "id": "pYW3STVfX0BN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "spacy doesn't support stemming but nltk supports both stemming and lemmatization."
      ],
      "metadata": {
        "id": "R9467smtZVOb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o5hpJvZKXqqc"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming in NLTK"
      ],
      "metadata": {
        "id": "16LA3drZaegT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "GiCkLwQnaa08"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\"]\n",
        "\n",
        "for word in words:\n",
        "    print(word, \"|\", stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iodFB2OhajIK",
        "outputId": "f9b1a4e2-b3cb-46dc-c83a-3df8971be8e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating | eat\n",
            "eats | eat\n",
            "eat | eat\n",
            "ate | ate\n",
            "adjustable | adjust\n",
            "rafting | raft\n",
            "ability | abil\n",
            "meeting | meet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmatization in Spacy"
      ],
      "metadata": {
        "id": "Ovx7Y5U-apDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(\"eating eats eat ate adjustable rafting ability meeting better\")\n",
        "for token in doc:\n",
        "    print(token, \" | \", token.lemma_, \" | \", token.lemma) # token.lemma is a uniques identifier for each word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwdlhldzalHb",
        "outputId": "a0def827-57b9-4672-b608-14276738d90f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating  |  eat  |  9837207709914848172\n",
            "eats  |  eat  |  9837207709914848172\n",
            "eat  |  eat  |  9837207709914848172\n",
            "ate  |  eat  |  9837207709914848172\n",
            "adjustable  |  adjustable  |  6033511944150694480\n",
            "rafting  |  raft  |  7154368781129989833\n",
            "ability  |  ability  |  11565809527369121409\n",
            "meeting  |  meeting  |  14798207169164081740\n",
            "better  |  well  |  4525988469032889948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Customizing lemmatizer"
      ],
      "metadata": {
        "id": "zwNsjh7cbmtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tMu03d9auMy",
        "outputId": "9ce36422-cdbf-469f-bde3-4d0574bfb8a0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ar = nlp.get_pipe('attribute_ruler')\n",
        "\n",
        "ar.add([[{\"TEXT\":\"Bro\"}],[{\"TEXT\":\"Brah\"}]],{\"LEMMA\":\"Brother\"})\n",
        "\n",
        "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
        "for token in doc:\n",
        "    print(token.text, \"|\", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvoZ5NX2btaG",
        "outputId": "1909ba25-5c67-4e2c-e1bc-b49f12e46288"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bro | Brother\n",
            ", | ,\n",
            "you | you\n",
            "wanna | wanna\n",
            "go | go\n",
            "? | ?\n",
            "Brah | Brother\n",
            ", | ,\n",
            "do | do\n",
            "n't | not\n",
            "say | say\n",
            "no | no\n",
            "! | !\n",
            "I | I\n",
            "am | be\n",
            "exhausted | exhaust\n"
          ]
        }
      ]
    }
  ]
}